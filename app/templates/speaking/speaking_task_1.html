{% extends "layout.html" %}

{% block title %}Responding to questions{% endblock %}

{% block content %}
<h1 class="page-title">Responding to questions <img src="{{ url_for('static', filename='images/speaking.jpg') }}" alt="Speaking icon" class="title-icon"></h1>

<div class="container mt-4">
    <div id="taskContainer">
        <!-- Video player -->
        <video id="taskVideo" class="w-100 mb-3" controls>
            <source id="videoSource" src="" type="video/mp4">
            Your browser does not support the video element.
        </video>

        <!-- Recording interface (hidden initially) -->
        <div id="recordingInterface" class="text-center mb-3" style="display: none;">
            <button id="submitButton" class="btn btn-primary">Submit Recording Early</button>
        </div>

        <!-- Progress indicator -->
        <div class="progress mb-3">
            <div id="progressBar" class="progress-bar" role="progressbar" style="width: 0%"></div>
        </div>
    </div>
</div>

<script>
const videos = {
    intro: '/static/videos/task1/intro.mp4',
    Q1: '/static/videos/task1/Q1.mp4',
    Q2: '/static/videos/task1/Q2.mp4',
    Q3: '/static/videos/task1/Q3.mp4'
};

let currentStage = 'intro';
let mediaRecorder = null;
let audioChunks = [];
let recordingTimeout = null;
let recordingStartTimeout = null;
let isSubmitting = false;
let responses = {};

const videoElement = document.getElementById('taskVideo');
const recordingInterface = document.getElementById('recordingInterface');
const submitButton = document.getElementById('submitButton');
const progressBar = document.getElementById('progressBar');

function updateProgress() {
    const stages = ['intro', 'Q1', 'Q2', 'Q3'];
    const currentIndex = stages.indexOf(currentStage);
    const progress = (currentIndex / (stages.length - 1)) * 100;
    progressBar.style.width = `${progress}%`;
}

async function startRecording(duration) {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            await handleRecording(audioBlob);
            stream.getTracks().forEach(track => track.stop());
        };

        mediaRecorder.start();
        recordingInterface.style.display = 'block';
        // Reset button state at the start of each recording
        updateSubmitButton('reset');
        
        // Set timeout for automatic submission
        recordingTimeout = setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                updateSubmitButton('auto');
                mediaRecorder.stop();
            }
        }, duration * 1000);
    } catch (error) {
        console.error('Error starting recording:', error);
        alert('Failed to start recording. Please ensure microphone access is granted.');
    }
}

async function handleRecording(audioBlob) {
    if (isSubmitting) return;
    isSubmitting = true;

    try {
        // Submit the current response for transcription
        await submitResponse(audioBlob);
        
        // Move to next question or get feedback
        if (currentStage === 'Q3') {
            // All recordings done, get feedback for all responses
            await getFeedbackAndRedirect();
        } else {
            await playNextVideo();
        }
    } catch (error) {
        console.error('Error:', error);
        alert('There was an error processing your recording. Please try again.');
        // Reset button state if there's an error
        updateSubmitButton('reset');
    } finally {
        isSubmitting = false;
    }
}

async function submitResponse(audioBlob) {
    const formData = new FormData();
    const questionNumber = currentStage.replace('Q', '');
    
    // Create a File object from the Blob
    const audioFile = new File([audioBlob], 'recording.webm', { type: 'audio/webm' });
    formData.append('audio_file', audioFile);
    formData.append('question_number', questionNumber);

    try {
        const response = await fetch('/speaking/speaking_task_1_transcribe', {
            method: 'POST',
            body: formData
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error || 'Failed to submit response');
        }

        const data = await response.json();
        if (data.error) {
            throw new Error(data.error);
        }
        
        return data;
        
    } catch (error) {
        console.error('Submission error:', error);
        throw new Error('Failed to submit recording. Please try again.');
    }
}

async function getFeedbackAndRedirect() {
    try {
        const response = await fetch('/speaking/speaking_task_1_generate_feedback', {
            method: 'POST'
        });

        if (!response.ok) {
            throw new Error('Failed to generate feedback');
        }

        window.location.href = '/speaking/speaking_task_1_feedback';
    } catch (error) {
        console.error('Error generating feedback:', error);
        alert('There was an error generating feedback. Please try again.');
    }
}

async function playNextVideo() {
    // Clear any existing timeouts
    if (recordingStartTimeout) {
        clearTimeout(recordingStartTimeout);
    }
    if (recordingTimeout) {
        clearTimeout(recordingTimeout);
    }

    const stages = ['intro', 'Q1', 'Q2', 'Q3'];
    const currentIndex = stages.indexOf(currentStage);
    const nextStage = stages[currentIndex + 1];
    
    if (nextStage) {
        currentStage = nextStage;
        videoElement.src = videos[currentStage];
        videoElement.play();
        updateProgress();

        if (nextStage.startsWith('Q')) {
            // Hide recording interface and reset button state
            recordingInterface.style.display = 'none';
            updateSubmitButton('reset');
            
            // Set delay: 4 seconds for Q1, 8 seconds for Q2 and Q3
            const delay = nextStage === 'Q1' ? 4000 : 8000;
            
            await new Promise(resolve => {
                recordingStartTimeout = setTimeout(async () => {
                    await startRecording(32); // 32 seconds recording time
                    resolve();
                }, delay);
            });
        }
    }
}

// Event listeners
videoElement.addEventListener('ended', async () => {
    if (currentStage === 'intro') {
        await playNextVideo();
    } else if (currentStage.startsWith('Q') && mediaRecorder && mediaRecorder.state === 'recording') {
        // If the video ends while still recording, let the recording timeout handle it
        console.log('Video ended, waiting for recording to complete...');
    }
});

function updateSubmitButton(state) {
    const submitButton = document.getElementById('submitButton');
    
    switch(state) {
        case 'manual':
            submitButton.className = 'btn btn-warning';
            submitButton.textContent = 'Submitting response, please wait...';
            submitButton.disabled = true;
            break;
        case 'auto':
            submitButton.className = 'btn btn-warning';
            submitButton.textContent = 'Submitting response, please wait...';
            submitButton.disabled = true;
            break;
        case 'reset':
            submitButton.className = 'btn btn-primary';
            submitButton.textContent = 'Submit Recording Early';
            submitButton.disabled = false;
            break;
        default:
            submitButton.className = 'btn btn-primary';
            submitButton.textContent = 'Submit Recording Early';
            submitButton.disabled = false;
    }
}

// Update the submit button click handler
submitButton.addEventListener('click', () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        updateSubmitButton('manual');
        clearTimeout(recordingTimeout);
        mediaRecorder.stop();
    }
});

// Handle page unload to clean up
window.addEventListener('beforeunload', () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
    }
    if (recordingStartTimeout) {
        clearTimeout(recordingStartTimeout);
    }
    if (recordingTimeout) {
        clearTimeout(recordingTimeout);
    }
});

// Start with the intro video
videoElement.src = videos.intro;
</script>
{% endblock %}
