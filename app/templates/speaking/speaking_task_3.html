{% extends "layout.html" %}

{% block title %}Interacting{% endblock %}

{% block content %}
<h1 class="page-title">Interacting <img src="{{ url_for('static', filename='images/speaking.jpg') }}" alt="Speaking icon" class="title-icon"></h1>

<div class="container mt-4">
    <div id="taskContainer">
        <!-- Video player -->
        <video id="taskVideo" class="w-100 mb-3" controls>
            <source id="videoSource" src="" type="video/mp4">
            Your browser does not support the video element.
        </video>

        <!-- Recording interface (hidden initially) -->
        <div id="recordingInterface" class="text-center mb-3" style="display: none;">
            <button id="submitButton" class="btn btn-primary">Submit Recording Early</button>
        </div>

        <!-- Progress indicator -->
        <div class="progress mb-3">
            <div id="progressBar" class="progress-bar" role="progressbar" style="width: 0%"></div>
        </div>
    </div>
</div>

<script>
const videos = {
    intro: '/static/videos/task3/intro.mp4',
    prompt: '/static/videos/task3/prompt.mp4',
    speaking: '/static/videos/task3/speaking.mp4',
    followup: '/static/videos/task3/followup.mp4'
};

let currentStage = 'intro';
let mediaRecorder = null;
let audioChunks = [];
let recordingTimeout = null;
let recordingStartTimeout = null;
let isSubmitting = false;

const videoElement = document.getElementById('taskVideo');
const recordingInterface = document.getElementById('recordingInterface');
const submitButton = document.getElementById('submitButton');
const progressBar = document.getElementById('progressBar');

function updateProgress(stage) {
    const progress = {
        'intro': 25,
        'prompt': 50,
        'speaking': 75,
        'followup': 100
    };
    progressBar.style.width = `${progress[stage]}%`;
}

async function startRecording(duration) {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
        };

        mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            await submitRecording(audioBlob);
            stream.getTracks().forEach(track => track.stop());
        };

        mediaRecorder.start();
        recordingInterface.style.display = 'block';
        
        // Set timeout for automatic submission
        recordingTimeout = setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }, duration * 1000);
    } catch (error) {
        console.error('Error starting recording:', error);
        alert('Failed to start recording. Please ensure microphone access is granted.');
    }
}

async function submitRecording(audioBlob) {
    if (isSubmitting) return;
    isSubmitting = true;

    try {
        updateSubmitButton('manual');
        
        const formData = new FormData();
        formData.append('audio_file', audioBlob);
        formData.append('stage', currentStage === 'speaking' ? 'main' : 'followup');
        formData.append('timestamp', Date.now());

        console.log(`Submitting ${currentStage} recording with stage: ${formData.get('stage')}`);
        const response = await fetch('/speaking/speaking_task_3_submit', {
            method: 'POST',
            body: formData,
            cache: 'no-cache'
        });
        
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        
        const data = await response.json();
        
        if (!data.success) {
            throw new Error('Submission was not successful');
        }

        console.log(`Successfully submitted ${currentStage} recording`);
        
        if (currentStage === 'speaking') {
            console.log('Moving to follow-up video...');
            await new Promise(resolve => setTimeout(resolve, 1000));
            await playNextVideo();
        } else if (currentStage === 'followup') {
            console.log('Redirecting to feedback page...');
            await new Promise(resolve => setTimeout(resolve, 1000));
            window.location.href = `/speaking/speaking_task_3_feedback?t=${Date.now()}`;
        }
    } catch (error) {
        console.error('Error:', error);
        alert('There was an error submitting your recording. Please try again.');
        updateSubmitButton('reset');
    } finally {
        isSubmitting = false;
    }
}

function updateSubmitButton(state) {
    const submitButton = document.getElementById('submitButton');
    
    switch(state) {
        case 'manual':
            submitButton.className = 'btn btn-warning';
            submitButton.textContent = 'Submitting response, please wait...';
            submitButton.disabled = true;
            break;
        case 'auto':
            submitButton.className = 'btn btn-warning';
            submitButton.textContent = 'Submitting response, please wait...';
            submitButton.disabled = true;
            break;
        case 'reset':
            submitButton.className = 'btn btn-primary';
            submitButton.textContent = 'Submit Recording Early';
            submitButton.disabled = false;
            break;
        default:
            submitButton.className = 'btn btn-primary';
            submitButton.textContent = 'Submit Recording Early';
            submitButton.disabled = false;
    }
}

async function playNextVideo() {
    // Clear any existing timeouts
    if (recordingStartTimeout) {
        clearTimeout(recordingStartTimeout);
    }
    if (recordingTimeout) {
        clearTimeout(recordingTimeout);
    }

    const stages = ['intro', 'prompt', 'speaking', 'followup'];
    const currentIndex = stages.indexOf(currentStage);
    const nextStage = stages[currentIndex + 1];
    
    if (nextStage) {
        currentStage = nextStage;
        videoElement.src = videos[currentStage];
        videoElement.play();
        updateProgress(currentStage);

        // Hide recording interface and reset button state
        recordingInterface.style.display = 'none';
        updateSubmitButton('reset');

        // Set up recording based on the stage
        if (currentStage === 'speaking') {
            recordingInterface.style.display = 'none';
            // Wait 4 seconds before starting the recording
            await new Promise(resolve => {
                recordingStartTimeout = setTimeout(async () => {
                    await startRecording(60); // 1 minute
                    resolve();
                }, 4000); // 4 seconds delay
            });
        } else if (currentStage === 'followup') {
            recordingInterface.style.display = 'none';
            // Wait 8 seconds before starting the recording
            await new Promise(resolve => {
                recordingStartTimeout = setTimeout(async () => {
                    await startRecording(30); // 30 seconds
                    resolve();
                }, 8000); // 8 seconds delay
            });
        }
    }
}

// Event listeners
videoElement.addEventListener('ended', async () => {
    if (currentStage === 'intro' || currentStage === 'prompt') {
        await playNextVideo();
    } else if (currentStage === 'speaking' && mediaRecorder && mediaRecorder.state === 'recording') {
        // If speaking video ends while still recording, let the recording timeout handle it
        console.log('Speaking video ended, waiting for recording to complete...');
    }
    // Don't automatically play followup video - it will be played after submission completes
});

submitButton.addEventListener('click', () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        updateSubmitButton('manual');
        // Clear the recording timeout
        if (recordingTimeout) {
            clearTimeout(recordingTimeout);
        }
        // Stop the recording
        mediaRecorder.stop();
        // Stop all tracks in the stream
        mediaRecorder.stream.getTracks().forEach(track => track.stop());
    }
});

// Handle page unload to clean up
window.addEventListener('beforeunload', () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
    }
    if (recordingStartTimeout) {
        clearTimeout(recordingStartTimeout);
    }
    if (recordingTimeout) {
        clearTimeout(recordingTimeout);
    }
});

// Start with the first video
videoElement.src = videos.intro;
</script>
{% endblock %}